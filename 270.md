# WIP: [270](https://github.com/cockroachdb/pebble/issues/270) Handle background errors

The task involves introducing the
[ErrorHandler](https://github.com/facebook/rocksdb/blob/master/db/error_handler.h)
API, an instance of which is kept in
[DB](https://github.com/facebook/rocksdb/blob/master/db/db_impl/db_impl.h#L2062).
Various code paths use the
[ErrorHandler::SetBGError](https://github.com/facebook/rocksdb/blob/master/db/error_handler.h#L35)
to set the error upon encountering an error. Various code paths also
consult the `ErrorHandler` using
[IsDBStopped](https://github.com/facebook/rocksdb/blob/master/db/error_handler.h#L43),
[IsBGWorkStopped](https://github.com/facebook/rocksdb/blob/master/db/error_handler.h#L48)
to know if the DB has been placed in read-only mode and hence stop the
foreground, background writes respectively.

RocksDB’s overview of their background error handling is described
[here](https://github.com/facebook/rocksdb/wiki/Background-Error-Handling). It
is advised to read it before proceeding.

The below outlines the code paths in RocksDB that set the error. Some paths might not be relevant because they simply don’t
happen in Pebble and hence are omitted. For example, Pebble doesn't have Column Families or
Pipelined writes.



Note: There might be cases that only happen in Pebble. We should look out for them too once we have complete sense of what failures usually happen and are critical for us to place the DB in read only mode.

Format:
## [BackgroundErrorReason](https://github.com/facebook/rocksdb/blob/master/include/rocksdb/listener.h#L115)
### API which is the source of the error
#### Description
Describes what the API does.
#### Error scenarios

Various code paths that use the API and hence cause the bg error to set.

1.  Scenario A.
    
    #### RocksDB code path
    #### Pebble code path
    #### Questions
    #### Action item
    Describes the code change required.
    #### Recovery
    Steps to take for recovery. RocksDB doesn't state them on a case by case basis, but
    it is useful to think of them.
 

## kMemtable

This `BackgroundErrorReason` is considered `Status::Severity::kFatalError` no matter the
[Status::Code](https://github.com/facebook/rocksdb/blob/master/include/rocksdb/status.h#L46), [Status::SubCode](https://github.com/facebook/rocksdb/blob/master/include/rocksdb/status.h#L68) and hence sets the DB in read only mode. See the
severity mapping [here](https://github.com/facebook/rocksdb/blob/master/db/error_handler.cc#L117).

### ReadRecordFromWriteBatch

#### Description
When inserting records from the user provided `WriteBatch` into memtable,
the records are read one by one from the
batch and this read could fail because of a corrupt batch. Corrupt means if it
could not be decoded.

#### Error scenarios

1.  DB::WriteImpl 

    `WriteImpl` involves first writing the user key, value to WAL and then to
    memtable. If the write to memtable later fails the state would've diverged
    and hence requires fixing. See comment [here](https://github.com/facebook/rocksdb/blob/master/db/db_impl/db_impl_write.cc#L826).

    #### RocksDB code path

    ```
    DBImpl::WriteImpl  
    WriteBatchInternal::InsertInto  
    WriteBatch::Iterate  
    WriteBatchInternal::Iterate  
    ReadRecordFromWriteBatch returns Status::Corruption
    ```

    #### Pebble code path
    ```
    DB.Apply
    commitPipeline.Commit
    DB.commitApply
    memTable.apply panics with "pebble: inconsistent batch count" when BatchReader.Next returns false
    ```
    #### Questions

    Q. How could the batch get corrupted? RocksDB encodes the batch itself. The
    `WriteBatch::rep_` to which user given key, value are appended is also not
    user exposed. So what could lead to batch corruption? The question applies to Pebble as well.

    #### Action item

    Since there is atleast a *possibility* of the decoding failure, we need to handle the case by not panicking, propagating the error up and
    placing the DB in read-only mode.

    #### Recovery

    Since the batch is incorrectly encoded and simply re-reading the WAL and
    constructing the memtable would again fail, we probably need to reject the
    write by removing the batch from the WAL manually.

### DBImpl::SwitchMemtable

#### Description

`SwitchMemtable` is used to create a new memtable. This entails creating a new WAL, flushing the in memory buffer of
the current WAL and syncing the WAL. Failure in doing any of that
leads to setting the background error.

#### Error scenarios

1. Failing to create a new WAL file.

    #### RocksDB code path

    ```
    DBImpl::SwitchMemtable
    DBImpl::CreateWAL
    NewWritableFile
    PosixFileSystem::NewWritableFile
    PosixFileSystem::OpenWritableFile could fail with IOError("While open a file for appending", fname, errno) if the open syscall fails.
    ```
    Method [IOError](https://github.com/facebook/rocksdb/blob/master/env/io_posix.cc#L57) creates a `Status` with `IOError` as the `code_` and
    `subcode_` depending on the errno.

    #### Pebble code path
    ```
    DB.makeRoomForWrite(nil)
    FS.Create
    os.OpenFile
    openFileNolog
    syscall.Open
    ```
    
    #### Questions
    Q. Could we treat certain [errno](http://man7.org/linux/man-pages/man2/open.2.html#ERRORS) less severly? RocksDB treats all the same.
    
    #### Action item
    Instead of panicking in `DB.makeRoomForWrite` we return the error up and
    set the bg error.

    #### Recovery

    Depends on the specific [Errno](https://golang.org/pkg/syscall/#Errno) and
    requires fixing the cause manually.
    For example if it
    [IsPermission](https://golang.org/pkg/os/#IsPermission) error, then
    resolution is to give the permission.

2.  Failing to flush the in memory buffer or sync the current WAL.

    #### RocksDB code path

    Flush failure.

    ```
    DBImpl::SwitchMemtable
    Writer::WriteBuffer
    WritableFileWriter::Flush
    WritableFileWriter::WriteBuffered
    PosixWritableFile::Append
    write syscall
    ```

    Sync failure.

    ```
    DBImpl::SwitchMemtable
    Writer::WriteBuffer
    WritableFileWriter::Flush
    WritableFileWriter::RangeSync
    FSWritableFile::RangeSync
    PosixWritableFile::Sync
    fdatasync syscall
    ```

    #### Pebble code path

    Flush failure.
    ```
    DB.makeRoomForWrite(nil)
    LogWriter.Close waits for LogWriter.flushLoop
                              LogWriter.flushPending
                              LogWriter.w.write
                              os.File.Write
    ```

    Sync failure.
    ```
    DB.makeRoomForWrite(nil)
    LogWriter.Close
    syncer.Sync
    os.File.Sync
    ```
    #### Questions

    #### Action item
    Instead of panicking in `DB.makeRoomForWrite` we return the error up and
    also set the bg error.

    #### Recovery
    TODO



#### Usages of SwitchMemtable

Listing the higher level code paths in RocksDB that call into `SwitchMemtable`.

##### FlushMemtable

```
DBImpl::FlushMemtable
DBImpl::SwitchMemtable
```

Some instances of where `FlushMemtable` is called:
* DBImpl::Flush (FlushReason::kManualFlush)
* DBImpl::CompactRange (FlushReason::kManualCompaction)
* DBImpl::IngestExternalFile (FlushReason::kExternalFileIngestion)
* ErrorHandler::RecoverFromBGError->DBImpl::ResumeImpl
  (FlushReason::kErrorRecovery)
* DBImpl::CancelAllBackgroundWork (FlushReason::kShutDown)


##### Write batch

```
DBImpl::WriteImpl
DBImpl::PreprocessWrite
DBImpl::ScheduleFlushes
DBImpl::SwitchMemtable
```

```
DBImpl::WriteImpl
DBImpl::PreprocessWrite
DBImpl::HandleWriteBufferFull
DBImpl::SwitchMemtable
```

```
DBImpl::WriteImpl
DBImpl::PreprocessWrite
DBImpl::SwitchWAL
DBImpl::SwitchMemtable
```

## kFlush

This background error is set if a failure occurs during
memtable flush  and `DBOptions.paranoid_checks` is true (by default true). If it is false,
this background error is not set. Here's the error severity mapping:

|Status|Severity|
|------|--------|
|kIOError with subcode kNoSpace|kHardError|
|kCorruption|kUnrecoverableError|
|kIOError|kFatalError|
|Any other error|kFatalError|

The only error whose severity is decided irrespective of `paranoid_checks` is
`IOError` with subcode `kSpaceLimit`. Its severity is always `kHardError`.
 
Difference between `kSpaceLimit`, `kNoSpace`: 
* `kSpaceLimit` is raised *after* a successful flush by checking with
`SstFileManager.IsMaxAllowedSpaceReached()` if the configured max amount of space
is exceeded after the flush added new sstables.
* `kNoSpace` is the `ENOSPC` `errno` returned by certain OS system calls. For example when writing to a file and there's no space
  left on the drive.

#### Questions
Q. Why is this bg_error only set if `paranoid_checks` is enabled?  
A. Failures do not result in loss of data and since data is still present in
memtable, the flush can be safely retried. Also the side effect of
leaving SSTables of an incomplete flush is dealt by [removing them](https://github.com/cockroachdb/pebble/blob/de7fc1b547d5c7f390ae3a8162289f2dc7efab6a/compaction.go#L1249).


### DBImpl::FlushMemTableToOutputFile

#### Description

Operations involved in flushing memtable to disk:
* SSTable file creation
* Compaction iteration over memtables
* Adding entries to sstable
* Recording version edit in manifest

#### RocksDB code path
    ```
    DBImpl::BackgroundFlush
    DBImpl::FlushMemTablesToOutputFiles
    DBImpl::FlushMemTableToOutputFile
    FlushJob::Run
    FlushJob::WriteLevel0Table
    BuildTable
    ...
    ```

#### Error scenarios


|Operation|RocksDB code path|Pebble code path (TODO) | Error|Severity mapping|
|---|---|---|---|---|
|SSTable file creation failure|[BuildTable](https://github.com/facebook/rocksdb/blob/5c19a441c42fe516e3b9685a7d9b30d2a9234065/db/builder.cc#L125)||IOError|[Depends on errno](https://github.com/facebook/rocksdb/blob/eeb3cf3f58385eac17654fcfeaf288e568673db8/env/io_posix.cc#L57)|
|No merge operator defined.|[CompactionIterator::NextFromInput](https://github.com/facebook/rocksdb/blob/5c19a441c42fe516e3b9685a7d9b30d2a9234065/db/compaction/compaction_iterator.cc#L566)||Status::InvalidArgument("merge_operator is not properly initialized.")|kFatalError|
|Merge processing failure|[MergeHelper::TimedFullMerge](https://github.com/facebook/rocksdb/blob/5c19a441c42fe516e3b9685a7d9b30d2a9234065/db/merge_helper.cc#L101)||Status::Corruption("Error: Could not perform merge.")|kUnrecoverableError|
|Adding data, index, filter block to SSTable|[BlockBasedTableBuilder::WriteRawBlock](https://github.com/facebook/rocksdb/blob/5c19a441c42fe516e3b9685a7d9b30d2a9234065/table/block_based/block_based_table_builder.cc#L1003)||IOError|[Depends on errno](https://github.com/facebook/rocksdb/blob/eeb3cf3f58385eac17654fcfeaf288e568673db8/env/io_posix.cc#L57)|
|Checking SSTable constraints are obeyed|[VersionBuilder::CheckConsistency](https://github.com/facebook/rocksdb/blob/5c19a441c42fe516e3b9685a7d9b30d2a9234065/db/version_builder.cc#L200)||Status::Corruption|kUnrecoverableError|
|Write version edit to manifest log|[VersionSet::ProcessManifestWrites](https://github.com/facebook/rocksdb/blob/5c19a441c42fe516e3b9685a7d9b30d2a9234065/db/version_set.cc#L3910)||IOError|[Depends on errno](https://github.com/facebook/rocksdb/blob/eeb3cf3f58385eac17654fcfeaf288e568673db8/env/io_posix.cc#L57)|
|Sync manifest|[VersionSet::ProcessManifestWrites](https://github.com/facebook/rocksdb/blob/5c19a441c42fe516e3b9685a7d9b30d2a9234065/db/version_set.cc#L3918)||IOError|[Depends on errno](https://github.com/facebook/rocksdb/blob/eeb3cf3f58385eac17654fcfeaf288e568673db8/env/io_posix.cc#L57)|
|Make new manifest file created, current|[VersionSet::ProcessManifestWrites](https://github.com/facebook/rocksdb/blob/5c19a441c42fe516e3b9685a7d9b30d2a9234065/db/version_set.cc#L3931)||IOError|[Depends on errno](https://github.com/facebook/rocksdb/blob/eeb3cf3f58385eac17654fcfeaf288e568673db8/env/io_posix.cc#L57)|


## kWriteCallback

 This background error is set if an error occurs in the write path
 `DB::WriteImpl` and if `DBOptions.paranoid_checks` is true (by default true).
 If it is false,
this background error is not set. Here's the error severity mapping:

|Status|Severity|
|------|--------|
|kIOError with subcode kNoSpace|kHardError|
|kCorruption|kUnrecoverableError|
|kIOError|kFatalError|
|Any other error|kFatalError|


Although the error is called `kWriteCallback`, [it is set](https://github.com/facebook/rocksdb/blob/9eca6d651d84542f0098d34eca104b51cbc42093/db/db_impl/db_impl_write.cc#L415) even if [no
WriteCallback is
given](https://github.com/facebook/rocksdb/blob/9eca6d651d84542f0098d34eca104b51cbc42093/db/write_thread.h#L222)
as is the case with `DB::WriteImpl` whose `callback` parameter is `nullptr`.



### DB::WriteImpl

Failures in `DBImpl::WriteToWAL` and `DB::DBImpl::PreprocessWrite`.  
TODO explain what these APIs do and what failures happen in them.

#### Questions
Q. Why is it called `kWriteCallback` instead of `kWrite`? Even though this
error is set when *any* failure occurs during a write *after* the callback is successful. Since we don't have the
`DB::WriteWithCallback` API should we call it `kWrite`? OR for source code
symmetry with RocksDB let it be called `kWriteCallback`? I prefer the latter.

Q. Both `kWriteCallback` and `kMemtable` are set in the code path
`DB::WriteImpl`. When is each one set?
A. `kMemtable` is set when there are failures in writing the batch to
memtable. Each of the parallel memtable writer threads could fail when doing this
and hence keep their [own
status](https://github.com/facebook/rocksdb/blob/234e2ed5b69a45cfd180d272e47a3bb9481bcb7f/db/write_thread.h#L130).
Finally they [propagate their error to their write
group](https://github.com/facebook/rocksdb/blob/234e2ed5b69a45cfd180d272e47a3bb9481bcb7f/db/write_thread.cc#L587).

`kWriteCallback` is set for any failure that occurs before the memtable write.
This includes `DBImpl::WriteToWAL` and `DB::DBImpl::PreprocessWrite`.

### DBImpl::FlushWAL
By default RocksDB flushes the WAL buffer to OS [after every
write](https://github.com/facebook/rocksdb/blob/eeb3cf3f58385eac17654fcfeaf288e568673db8/db/log_writer.cc#L108).
Hence any flush failures directly lie in the `DB:WriteImpl` code path and
set the bg_error to `kWriteCallback`. However if
`DBOptions::manual_wal_flush` is true, then flush is not invoked after every
write and is left upto the user to issue a `DB::FlushWAL`. This call also sets
`kWriteCallback` if a failure occurs during WAL flush.


Pebble does flushing of WALs differently. It does it in the background in a
`LogWriter.flushLoop` and upon any errors propagates it to the foreground by
setting the `LogWriter.err` which is read in [LogWriter.SyncRecord](https://github.com/cockroachdb/pebble/blob/de7fc1b547d5c7f390ae3a8162289f2dc7efab6a/internal/record/log_writer.go#L547). Hence any future writes to WAL fail and 
would set the bg_err to `kWriteCallback`.

#### Questions

Q. Do we need a new kind of bg_error
called `kFlushWAL` since WAL flushes are done in background for Pebble?  
A. Maybe not. The intention of setting the `bg_error` is to stop further writes
and put the DB in read-only mode. Since we anyways propagate the err to the
foreground which results in setting the `bg_error` upon subsquent writes, we don't need to set the `bg_error` in `LogWriter.flushLoop`.


## kCompaction

TODO


# TODOs
Q. Only no space errors are recoverable. How is the recovery done?

Q. What is the degraded mode of `kSoftError`? What components are degraded and
how exactly? One degradation is limiting the size of compaction that can run.
See
[SstFileManagerImpl::EnoughRoomForCompaction](https://github.com/facebook/rocksdb/blob/eeb3cf3f58385eac17654fcfeaf288e568673db8/file/sst_file_manager_impl.cc#L186).

Q. Impact of setting a bg_error. What operations are affected/stopped? From
some recollection: stop compaction & fail any further writes.

Follow up on the [new changes introduced in
RocksDB](https://github.com/facebook/rocksdb/pull/6487) that handles IOErrors
as retryable/non-retryable.

# paranoid_checks

TODO enlist all the aggressive checking done if paranoid_checks is set to true.

#### Questions
Q. In what cases can we keep this false and what are the consequences of that?
